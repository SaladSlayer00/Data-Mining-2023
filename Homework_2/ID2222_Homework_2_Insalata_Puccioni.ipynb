{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d77a0d7",
   "metadata": {},
   "source": [
    "# ID2222 Data Mining - Homework 2\n",
    "\n",
    "Notebook by Beatrice Insalata, Laura Puccioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f418e4e",
   "metadata": {},
   "source": [
    "For this task, we are asked to implement the A-Priori algorithm to identify frequent itemsets with a support of at least 's' in a sales transactions dataset. We have used the Python language to evaluate and validate the A-Priori implementation on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0961e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Set, KeysView, FrozenSet\n",
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057aa995",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Our dataset consists of a sale transaction database (T10I4D100K). The dataset contains 100,000 baskets summing up to 1,010,228 items, with a market size of 870 different items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac6ee37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25,\n",
       "  52,\n",
       "  164,\n",
       "  240,\n",
       "  274,\n",
       "  328,\n",
       "  368,\n",
       "  448,\n",
       "  538,\n",
       "  561,\n",
       "  630,\n",
       "  687,\n",
       "  730,\n",
       "  775,\n",
       "  825,\n",
       "  834],\n",
       " [39, 120, 124, 205, 401, 581, 704, 814, 825, 834],\n",
       " [35, 249, 674, 712, 733, 759, 854, 950],\n",
       " [39, 422, 449, 704, 825, 857, 895, 937, 954, 964],\n",
       " [15, 229, 262, 283, 294, 352, 381, 708, 738, 766, 853, 883, 966, 978]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we read from a file .dat assuming that on every row of the file there is a basket of items and create a list of baskets\n",
    "\n",
    "with open('T10I4D100K.dat', \"r\") as f:\n",
    "    baskets = list(\n",
    "        map(\n",
    "            lambda basket: [int(item_id) for item_id in basket.split()],\n",
    "            f.read().splitlines()\n",
    "        )\n",
    "    )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a3a199",
   "metadata": {},
   "source": [
    "# A-Priori Algorithm Implementation\n",
    "\n",
    "The Apriori algorithm operates in two passes. In the initial pass, it scans through the baskets, counting the occurrences of each individual item (singletons). In the subsequent pass, the algorithm revisits the baskets, focusing only on pairs where both elements are identified as frequent during the first pass. This process continues iteratively, incrementing the itemset size with each pass. The primary aim is to efficiently identify and prune non-frequent itemsets, ultimately discovering frequent itemsets and their support levels in the dataset.\n",
    "\n",
    "The iterative nature of the algorithm allows it to progressively explore larger itemsets while leveraging the knowledge gained from previous passes. This two-pass strategy minimizes the need for multiple scans of the entire dataset and optimizes the discovery of frequent itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79728d1",
   "metadata": {},
   "source": [
    "## Pass 1 : Find frequent singletons\n",
    "\n",
    "During the initial pass, the Apriori algorithm identifies frequent single elements, or 1-itemsets, within the dataset. The term \"frequent\" here implies that these individual elements occur with a frequency at least equal to a specified threshold called \"support\". Essentially, this step involves finding and recording items that are individually popular or common, laying the foundation for subsequent steps in discovering larger sets of items with significant occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32a53e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes as arguments the set of baskets and the threshold called \"support\", \n",
    "and returns the set of frequent singletons, that is the frequent 1-item sets.\n",
    "\"\"\"\n",
    "def find_frequent_singletons_with_support(baskets, support):\n",
    "    \n",
    "    occurrences = {} # a dictionary containing occurence of items in baskets\n",
    "    for itemset in baskets:\n",
    "        for item in itemset:\n",
    "            if item not in occurrences: # this item didn't exist in previous baskets, initialize with 1\n",
    "                occurrences[item] = 1\n",
    "            else:\n",
    "                occurrences[item] += 1\n",
    "    print({key:value for key, value in occurrences.items() if value >= support})\n",
    "    return {key for key, value in occurrences.items() if value >= support}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88983911",
   "metadata": {},
   "source": [
    "We can visualize how the step 1 works on a small set of items, for example using the first 5 baskets of the given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec1e5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25, 52, 164, 240, 274, 328, 368, 448, 538, 561, 630, 687, 730, 775, 825, 834], [39, 120, 124, 205, 401, 581, 704, 814, 825, 834], [35, 249, 674, 712, 733, 759, 854, 950], [39, 422, 449, 704, 825, 857, 895, 937, 954, 964], [15, 229, 262, 283, 294, 352, 381, 708, 738, 766, 853, 883, 966, 978]]\n"
     ]
    }
   ],
   "source": [
    "example_dataset = baskets[0:5]\n",
    "print(example_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79064e",
   "metadata": {},
   "source": [
    "If, for instance, we want support = 2, we keep the elements that appear in the dataset at least 2 times. We can do this by hand and then check the correctness of the previous function. In this case 39 appears 2 times, 704 appears 2 times, 825 appears 3 times and 834 appears 2 times. So in the end we will have a list of singleton of this type: {39, 704, 825, 934}.\n",
    "Let's check this by calling the find_frequent_singletons_with_support function on the example_dataset with support = 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f66c9384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{825: 3, 834: 2, 39: 2, 704: 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{39, 704, 825, 834}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_frequent_singletons_with_support(example_dataset, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892381a",
   "metadata": {},
   "source": [
    "Devo finire da qui in poi, aggiungerò più esempi e spiegazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1fde02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(39, 834), (704, 825), (39, 704), (704, 834), (39, 825), (825, 834)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(39, 704, 834), (39, 704, 825), (704, 825, 834), (39, 825, 834)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_candidates(prev_frequent_itemsets, k):\n",
    "    candidates = set()\n",
    "    \n",
    "    # Ensure prev_frequent_itemsets only contains iterable elements\n",
    "    prev_frequent_itemsets = [itemset if isinstance(itemset, (list, tuple)) else [itemset] for itemset in prev_frequent_itemsets]\n",
    "\n",
    "    for i in range(len(prev_frequent_itemsets)):\n",
    "        for j in range(i + 1, len(prev_frequent_itemsets)):\n",
    "            union_set = set(prev_frequent_itemsets[i]) | set(prev_frequent_itemsets[j])\n",
    "            if len(union_set) == k + 1:\n",
    "                candidates.add(tuple(sorted(union_set)))\n",
    "    \n",
    "    return list(candidates)\n",
    "\n",
    "newset = generate_candidates(find_frequent_singletons_with_support(trial_baskets, 2), 1)\n",
    "print(newset)\n",
    "generate_candidates(newset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f456d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Frequent 1-itemsets: [(801, 862), (283, 346), (33, 346), (58, 354), (529, 598), (561, 888), (75, 438), (217, 346), (39, 825), (346, 515), (789, 829), (33, 217), (529, 782), (788, 956), (33, 283), (283, 515), (33, 515), (346, 561), (487, 510), (75, 684), (217, 283), (354, 752), (217, 515), (368, 829), (392, 862), (438, 684)]\n",
      "2\n",
      "Frequent 2-itemsets: [(217, 283, 346), (217, 346, 515), (33, 283, 515), (283, 346, 515), (33, 217, 515), (33, 217, 283), (217, 283, 515), (33, 283, 346), (33, 346, 515), (33, 217, 346)]\n",
      "3\n",
      "Frequent 3-itemsets: [(33, 217, 283, 515), (217, 283, 346, 515), (33, 217, 283, 346), (33, 283, 346, 515), (33, 217, 346, 515)]\n",
      "4\n",
      "Frequent 4-itemsets: [(33, 217, 283, 346, 515)]\n",
      "5\n",
      "Frequent 5-itemsets: []\n"
     ]
    }
   ],
   "source": [
    "def apriori(baskets, min_support):\n",
    "    frequent_itemsets = []\n",
    "    k = 0\n",
    "\n",
    "    # Find frequent 1-itemsets\n",
    "    frequent_singletons = find_frequent_singletons_with_support(baskets, min_support)\n",
    "    frequent_itemsets.extend(frequent_singletons)\n",
    "\n",
    "    while frequent_itemsets: #loop until there are no more frequent itemsets\n",
    "        k += 1\n",
    "        # Generate candidate itemsets\n",
    "        candidate_itemsets = generate_candidates(frequent_itemsets, k)\n",
    "\n",
    "        # Count occurrences of candidate itemsets\n",
    "        itemset_counts = {itemset: 0 for itemset in candidate_itemsets}\n",
    "        for basket in baskets:\n",
    "            for itemset in itemset_counts:\n",
    "                if set(itemset).issubset(basket):\n",
    "                    itemset_counts[itemset] += 1\n",
    "\n",
    "        # Filter frequent itemsets\n",
    "        frequent_itemsets = [itemset for itemset, count in itemset_counts.items() if count >= min_support]\n",
    "\n",
    "        # Print frequent itemsets of size k\n",
    "        print(f\"Frequent {k}-itemsets:\", frequent_itemsets)\n",
    "        \n",
    "apriori(baskets[0:1000], 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f96f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
